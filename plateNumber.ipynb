{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryasari/MLPlateNumber/blob/main/plateNumber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "084u8u0DpBlo"
      },
      "source": [
        "# Explore vision capabilities with the Gemini API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFWzQEqNosrS"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs/vision\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on ai.google.dev</a>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/vision.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/vision.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c5e92a74e64"
      },
      "source": [
        "The Gemini API is able to process images and videos, enabling a multitude of\n",
        " exciting developer use cases. Some of Gemini's vision capabilities include\n",
        " the ability to:\n",
        "\n",
        "*   Caption and answer questions about images\n",
        "*   Transcribe and reason over PDFs, including long documents up to 2 million token context window\n",
        "*   Describe, segment, and extract information from videos,\n",
        "including both visual frames and audio, up to 90 minutes long\n",
        "*   Detect objects in an image and return bounding box coordinates for them\n",
        "\n",
        "This tutorial demonstrates some possible ways to prompt the Gemini API with\n",
        "images and video input, provides code examples,\n",
        "and outlines prompting best practices with multimodal vision capabilities.\n",
        "All output is text-only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxCstRHvpX0r"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Before you use the File API, you need to install the Gemini API SDK package and configure an API key. This section describes how to complete these setup steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6J_rV2ipmj_"
      },
      "source": [
        "### Install the Python SDK and import packages\n",
        "\n",
        "The Python SDK for the Gemini API is contained in the [google-generativeai](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mN8x8DPgu9Kv"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NInUZ4hwDq6d"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0x3xmmWrDtEH"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Set up your API key\n",
        "\n",
        "The File API uses API keys for authentication and access. Uploaded files are associated with the project linked to the API key. Unlike other Gemini APIs that use API keys, your API key also grants access to data you've uploaded to the File API, so take extra care in keeping your API key secure. For more on keeping your keys\n",
        "secure, see [Best practices for using API\n",
        "keys](https://support.google.com/googleapi/answer/6310037).\n",
        "\n",
        "Store your API key in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or are unfamiliar with Colab Secrets, refer to the [Authentication quickstart](https://github.com/google-gemini/gemini-api-cookbook/blob/main/quickstarts/Authentication.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-z4zsCUlaru"
      },
      "source": [
        "## Prompting with images\n",
        "\n",
        "In this tutorial, you will upload images using the File API or as inline data and generate content based on those images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKNehP2tr3Cr"
      },
      "source": [
        "### Technical details (images)\n",
        "Gemini 1.5 Pro and Flash support a maximum of 3,600 image files.\n",
        "\n",
        "Images must be in one of the following image data [MIME types](https://developers.google.com/drive/api/guides/ref-export-formats):\n",
        "\n",
        "-   PNG - `image/png`\n",
        "-   JPEG - `image/jpeg`\n",
        "-   WEBP - `image/webp`\n",
        "-   HEIC - `image/heic`\n",
        "-   HEIF - `image/heif`\n",
        "\n",
        "Each image is equivalent to 258 tokens.\n",
        "\n",
        "While there are no specific limits to the number of pixels in an image besides the model’s context window, larger images are scaled down to a maximum resolution of 3072x3072 while preserving their original aspect ratio, while smaller images are scaled up to 768x768 pixels. There is no cost reduction for images at lower sizes, other than bandwidth, or performance improvement for images at higher resolution.\n",
        "\n",
        "For best results:\n",
        "\n",
        "*   Rotate images to the correct orientation before uploading.\n",
        "*   Avoid blurry images.\n",
        "*   If using a single image, place the text prompt after the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fa34d5c0db8"
      },
      "source": [
        "## Image input\n",
        "\n",
        "For total image payload size less than 20MB, it's recommended to either upload\n",
        "base64 encoded images or directly upload locally stored image files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8336e412da3e"
      },
      "source": [
        "### Base64 encoded images\n",
        "\n",
        "You can upload public image URLs by encoding them as Base64 payloads.\n",
        "You can use the httpx library to fetch the image URLs.\n",
        "The following code example shows how to do this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aa9a0e452544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "ab313e74-9519-457b-ccca-c21df2b3f021"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">A panoramic view of London showcases the city's iconic landmarks under a dramatic, cloud-filled sky. The London Eye Ferris wheel stands tall to the left, while the Houses of Parliament and its famous clock tower, Big Ben (now officially the Elizabeth Tower), take center stage.  The Shard skyscraper peeks out from behind the London skyline, offering a glimpse into the city's modern architecture. In the foreground, rooftops and a glimpse of St. Margaret's Church lead the eye towards the bustling streets below. The overcast weather adds a moody atmosphere to the vibrant cityscape."
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import httpx\n",
        "import base64\n",
        "\n",
        "# Retrieve an image\n",
        "image_path = \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Palace_of_Westminster_from_the_dome_on_Methodist_Central_Hall.jpg/2560px-Palace_of_Westminster_from_the_dome_on_Methodist_Central_Hall.jpg\"\n",
        "image = httpx.get(image_path)\n",
        "\n",
        "# Choose a Gemini model\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "\n",
        "# Create a prompt\n",
        "prompt = \"Caption this image.\"\n",
        "response = model.generate_content(\n",
        "    [\n",
        "        {\n",
        "            \"mime_type\": \"image/jpeg\",\n",
        "            \"data\": base64.b64encode(image.content).decode(\"utf-8\"),\n",
        "        },\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(\">\" + response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f47333dabe62"
      },
      "source": [
        "### Multiple images\n",
        "\n",
        "To prompt with multiple images in Base64 encoded format, you can do the\n",
        "following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2816ea3d2d91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "dd3a96de-e42a-4836-a5b3-b225dddab6c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Image 1 (London Skyline):**\n\n* Houses of Parliament (including Big Ben)\n* London Eye (ferris wheel)\n* The Shard (skyscraper)\n* River Thames\n* Various other buildings, including residential, commercial, and governmental structures\n* Cranes (indicating construction)\n* Trees and green spaces\n\n\n**Image 2 (Jetpack Backpack Sketch):**\n\n* Backpack shape\n* Padded strap support\n* USB-C charging port\n* Retractible boosters with flames/steam\n* Annotations indicating:\n    * Fits 18\" laptop\n    * Lightweight\n    * Looks like a normal backpack\n    * 15-minute battery life\n    * Steam-powered/Green/Clean propulsion"
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import httpx\n",
        "import base64\n",
        "\n",
        "# Retrieve two images\n",
        "image_path_1 = \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Palace_of_Westminster_from_the_dome_on_Methodist_Central_Hall.jpg/2560px-Palace_of_Westminster_from_the_dome_on_Methodist_Central_Hall.jpg\"\n",
        "image_path_2 = \"https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\"\n",
        "\n",
        "image_1 = httpx.get(image_path_1)\n",
        "image_2 = httpx.get(image_path_2)\n",
        "\n",
        "# Create a prompt\n",
        "prompt = \"Generate a list of all the objects contained in both images.\"\n",
        "\n",
        "response = model.generate_content([\n",
        "{'mime_type':'image/jpeg', 'data': base64.b64encode(image_1.content).decode('utf-8')},\n",
        "{'mime_type':'image/jpeg', 'data': base64.b64encode(image_2.content).decode('utf-8')}, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm862F3zthiI"
      },
      "source": [
        "### Upload one or more locally stored image files\n",
        "\n",
        "Alternatively, you can upload one or more locally stored image files..\n",
        "\n",
        "You can download and use our drawings of [piranha-infested waters](https://storage.googleapis.com/generativeai-downloads/images/piranha.jpg) and a [firefighter with a cat](https://storage.googleapis.com/generativeai-downloads/images/firefighter.jpg). First, save these files to your local directory.\n",
        "\n",
        "Then click **Files** on the left sidebar. For each file, click the **Upload** button, then navigate to that file's location and upload it:\n",
        "\n",
        "<img width=400 src=\"https://ai.google.dev/tutorials/images/colab_upload.png\">\n",
        "\n",
        "When the combination of files and system instructions that you intend to send is larger than 20 MB in size, use the File API to upload those files. Smaller files can instead be called locally from the Gemini API:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XzMhQ8MWub5_"
      },
      "outputs": [],
      "source": [
        "import PIL.Image\n",
        "\n",
        "sample_file_2 = PIL.Image.open('piranha.jpg')\n",
        "sample_file_3 = PIL.Image.open('cat-firefighter.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "da11223550a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "f9268af7-b9fc-4f52-f020-2254cc68cb4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "(Upbeat, slightly quirky music)\n\nGot a piranha, feeling glum?\nBelly red, fins feeling numb?\nFireman Fred's got the cure,\nFor fishy woes, he'll reassure!\n\n(Music becomes slightly more heroic)\n\nFrom burning buildings, cats he saves,\nBut even piranhas, he bravely waves \nHis magic net, no need to fear,\nFred's Aqua-Rescue is here!\n\n(Music returns to upbeat, ends with a splash sound)\n\nSo call on Fred, day or night,\nFor finned or furred, he'll make things right!\nFred's Aqua-Rescue, give us a call,\nHe'll save them all, big and small!\n*Splash!*\n"
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Create a prompt.\n",
        "prompt = \"Write an advertising jingle based on the items in both images.\"\n",
        "\n",
        "response = model.generate_content([sample_file_2, sample_file_3, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "736c83de95a1"
      },
      "source": [
        "Note that these inline data calls don't include many of the features available\n",
        "through the File API, such as getting file metadata,\n",
        "[listing](https://ai.google.dev/gemini-api/docs/vision?lang=python#list-files),\n",
        "or [deleting files](https://ai.google.dev/gemini-api/docs/vision?lang=python#delete-files)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d6f7af7c2ff"
      },
      "source": [
        "### Large image payloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsdNkDszLBmQ"
      },
      "source": [
        "#### Upload an image file using the File API\n",
        "\n",
        "When the combination of files and system instructions that you intend to send is larger than 20 MB in size, use the File API to upload those files.\n",
        "\n",
        "**NOTE**: The File API lets you store up to 20 GB of files per project, with a per-file maximum size of 2 GB. Files are stored for 48 hours. They can be accessed in that period with your API key, but cannot be downloaded from the API. It is available at no cost in all regions where the Gemini API is available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfa2VSqEsulq"
      },
      "source": [
        "Upload the image using [`media.upload`](https://ai.google.dev/api/rest/v1beta/media/upload) and print the URI, which is used as a reference in Gemini API calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2e9f9469b337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fef4841-ab24-4d5b-90f4-76985fa86fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  349k  100  349k    0     0   319k      0  0:00:01  0:00:01 --:--:--  319k\n"
          ]
        }
      ],
      "source": [
        "!curl -o jetpack.jpg https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "N9NxXGZKKusG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ed3cee5-7315-42e8-96b5-93443ee23a35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file 'Jetpack drawing' as: https://generativelanguage.googleapis.com/v1beta/files/or2e2oavr4h7\n"
          ]
        }
      ],
      "source": [
        "# Upload the file and print a confirmation.\n",
        "sample_file = genai.upload_file(path=\"jetpack.jpg\",\n",
        "                            display_name=\"Jetpack drawing\")\n",
        "\n",
        "print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cto22vhKOvGQ"
      },
      "source": [
        "The `response` shows that the File API stored the specified `display_name` for the uploaded file and a `uri` to reference the file in Gemini API calls. Use `response` to track how uploaded files are mapped to URIs.\n",
        "\n",
        "Depending on your use case, you can also store the URIs in structures such as a `dict` or a database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds5iJlaembWe"
      },
      "source": [
        "#### Verify image file upload and get metadata\n",
        "\n",
        "You can verify the API successfully stored the uploaded file and get its metadata by calling [`files.get`](https://ai.google.dev/api/rest/v1beta/files/get) through the SDK. Only the `name` (and by extension, the `uri`) are unique. Use `display_name` to identify files only if you manage uniqueness yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kLFsVLFHOWSV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1565b2b5-2024-4950-8a97-1f4f73483aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved file 'Jetpack drawing' as: https://generativelanguage.googleapis.com/v1beta/files/or2e2oavr4h7\n"
          ]
        }
      ],
      "source": [
        "file = genai.get_file(name=sample_file.name)\n",
        "print(f\"Retrieved file '{file.display_name}' as: {sample_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqzIGKBmnFoJ"
      },
      "source": [
        "Depending on your use case, you can store the URIs in structures, such as a `dict` or a database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPPOECHzsIGJ"
      },
      "source": [
        "#### Prompt with the uploaded image and text\n",
        "\n",
        "After uploading the file, you can make GenerateContent requests that reference the File API URI. Select the generative model and provide it with a text prompt and the uploaded image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZYVFqmLkl5nE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "ce52ed3b-7f26-40f7-b593-342644352f0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Manufacturing a jetpack backpack, even a conceptual steam-powered one, would be a complex process involving several stages and specialized manufacturers:\n\n1. **Backpack Construction:**  A traditional backpack manufacturer would handle this part.  They'd use durable, lightweight fabrics like ripstop nylon or Cordura, potentially incorporating reinforced areas for the jetpack components. Padded straps and back support would be crucial for comfort and weight distribution.\n\n2. **Booster Engine Manufacturing:** This would require a specialized engineering firm.  \n    * **Steam Generation:** A miniaturized boiler and burner system would be needed, possibly using a high-energy, compact fuel source. Precise machining and welding of heat-resistant materials (like stainless steel or titanium) would be essential. Safety features like pressure relief valves would be critical.\n    * **Nozzles:**  Precision-engineered nozzles would direct the steam for thrust, likely requiring 3D printing or CNC machining to achieve the required tolerances.\n    * **Retractable Mechanism:**  A compact and reliable system for deploying and retracting the boosters would be needed.  This could involve hydraulics, pneumatics, or electric motors, along with intricate linkages.\n\n3. **Power System Development:**  \n    * **Battery Production:** A high-capacity, fast-charging battery (likely lithium-ion) would power the ignition system, control circuits, and potentially assist the steam generation. This would involve collaboration with a battery manufacturer.\n    * **USB-C Charging Port Integration:**  Standard USB-C port components would need to be integrated into the backpack design.\n\n4. **Control System Design and Integration:** An electronics manufacturer would develop the circuitry and software to control the jetpack. This would involve:\n    * **Sensors:** Altitude, speed, and fuel level sensors would be crucial.\n    * **Microcontroller:** A powerful microcontroller would manage all systems and respond to user input.\n    * **User Interface:** A simple interface (perhaps a small display and buttons) would allow users to control the jetpack.\n\n5. **Assembly and Testing:** A dedicated facility would handle the final assembly and rigorous testing.  This would include:\n    * **Integration of Components:** Carefully fitting the boosters, power system, and control system within the backpack structure.\n    * **Quality Control:** Thoroughly testing all components and systems to ensure safety and functionality.  This might involve wind tunnel tests, thrust measurements, and flight simulations.\n    * **Safety Certification:** Meeting all relevant safety standards and obtaining necessary certifications before the product can be sold.\n\n6. **Distribution and Sales:**  Traditional retail channels or online sales platforms could handle distribution to consumers.\n\nThis hypothetical jetpack backpack would require collaboration between various specialized manufacturers, meticulous engineering, and rigorous testing.  While the steam-powered aspect is likely more science fiction than reality with current technology, the manufacturing process described above highlights the complexity of such a device.\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Prompt the model with text and the previously uploaded image.\n",
        "response = model.generate_content([sample_file, \"Describe how this product might be manufactured.\"])\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c63c1a7a8e32"
      },
      "source": [
        "## Capabilties\n",
        "\n",
        "This section outlines specific vision capabilities of the Gemini model, including object detection and bounding box coordinates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e16d742407a"
      },
      "source": [
        "### Get bounding boxes\n",
        "\n",
        "Gemini models are trained to return bounding box coordinates as relative widths or heights in the range of [0, 1]. These values are then scaled by 1000 and converted to integers. Effectively, the coordinates represent the bounding box on a 1000x1000 pixel version of the image. Therefore, you'll need to convert these coordinates back to the dimensions of your original image to accurately map the bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "778dd36334f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "outputId": "6ad897a1-e144-4688-9259-ea4842a0b944"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The image contains one piranha, and its bounding box is: [269, 156, 736, 843]."
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Create a prompt to detect bounding boxes.\n",
        "prompt = \"Return a bounding box for each of the objects in this image in [ymin, xmin, ymax, xmax] format.\"\n",
        "response = model.generate_content([sample_file_2, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8e422c55df2"
      },
      "source": [
        "The model returns bounding box coordinates in the format\n",
        "`[ymin, xmin, ymax, xmax]`. To convert these normalized coordinates\n",
        "to the pixel coordinates of your original image, follow these steps:\n",
        "\n",
        "1.    Divide each output coordinate by 1000.\n",
        "1.    Multiply the x-coordinates by the original image width.\n",
        "1.    Multiply the y-coordinates by the original image height.\n",
        "\n",
        "To explore more detailed examples of generating bounding box coordinates and\n",
        "visualizing them on images, review our [Object Detection cookbook example](https://github.com/google-gemini/cookbook/blob/main/examples/Object_detection.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaUZc1mvLkHY"
      },
      "source": [
        "## Prompting with video\n",
        "\n",
        "In this tutorial, you will upload a video using the File API and generate content based on those images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDN32NDPxXGX"
      },
      "source": [
        "### Technical details (video)\n",
        "\n",
        "Gemini 1.5 Pro and Flash support up to approximately an hour of video data.\n",
        "\n",
        "Video must be in one of the following video format [MIME types](https://developers.google.com/drive/api/guides/ref-export-formats):\n",
        "  -   `video/mp4`\n",
        "  -   `video/mpeg`\n",
        "  -   `video/mov`\n",
        "  -   `video/avi`\n",
        "  -   `video/x-flv`\n",
        "  -   `video/mpg`\n",
        "  -   `video/webm`\n",
        "  -   `video/wmv`\n",
        "  -   `video/3gpp`\n",
        "\n",
        "The File API service currently extracts image frames from videos at 1 frame per second (FPS) and audio at 1Kbps, single channel, adding timestamps every second. These rates are subject to change in the future for improvements in inference.\n",
        "\n",
        "**NOTE:** The finer details of fast action sequences may be lost at the 1 FPS frame sampling rate. Consider slowing down high-speed clips for improved inference quality.\n",
        "\n",
        "Individual frames are 258 tokens, and audio is 32 tokens per second. With metadata, each second of video becomes ~300 tokens, which means a 1M context window can fit slightly less than an hour of video.\n",
        "\n",
        "To ask questions about time-stamped locations, use the format `MM:SS`, where the first two digits represent minutes and the last two digits represent seconds.\n",
        "\n",
        "For best results:\n",
        "\n",
        "*   Use one video per prompt.\n",
        "*   If using a single video, place the text prompt after the video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNvhBdoDFnTC"
      },
      "source": [
        "### Upload a video file to the File API\n",
        "\n",
        "**NOTE**: The File API lets you store up to 20 GB of files per project, with a per-file maximum size of 2 GB. Files are stored for 48 hours. They can be accessed in that period with your API key, but they cannot be downloaded using any API. It is available at no cost in all regions where the Gemini API is available.\n",
        "\n",
        "The File API accepts video file formats directly. This example uses the short NASA film [\"Jupiter's Great Red Spot Shrinks and Grows\"](https://www.youtube.com/watch?v=JDi4IdtvDVE0). Credit: Goddard Space Flight Center (GSFC)/David Ladd (2018).\n",
        "\n",
        "> \"Jupiter's Great Red Spot Shrinks and Grows\" is in the public domain and does not show identifiable people. ([NASA image and media usage guidelines.](https://www.nasa.gov/nasa-brand-center/images-and-media/))\n",
        "\n",
        "Start by retrieving the short video:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "V4XeFdX1rxaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e97b486f-631c-4db1-f7c7-25ce385ba3f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-07 13:01:26--  https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.175.207, 142.251.10.207, 142.251.12.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.175.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 238090979 (227M) [video/mp4]\n",
            "Saving to: ‘GreatRedSpot.mp4’\n",
            "\n",
            "GreatRedSpot.mp4    100%[===================>] 227.06M  21.9MB/s    in 12s     \n",
            "\n",
            "2024-12-07 13:01:38 (19.3 MB/s) - ‘GreatRedSpot.mp4’ saved [238090979/238090979]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZusSiIg2T6ls"
      },
      "source": [
        "Upload the video to the File API and print the URI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_HzrDdp2Q1Cu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8ea20a61-b4ab-497d-d79f-40d3239ac8a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/hbhacw2ab69s\n"
          ]
        }
      ],
      "source": [
        "video_file_name = \"GreatRedSpot.mp4\"\n",
        "\n",
        "print(f\"Uploading file...\")\n",
        "video_file = genai.upload_file(path=video_file_name)\n",
        "print(f\"Completed upload: {video_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOZmTUb4FWOa"
      },
      "source": [
        "### Verify file upload and check state\n",
        "\n",
        "Verify the API has successfully received the files by calling the [`files.get`](https://ai.google.dev/api/rest/v1beta/files/get) method.\n",
        "\n",
        "**NOTE**: Video files have a `State` field in the File API. When a video is uploaded, it will be in the `PROCESSING` state until it is ready for inference. Only `ACTIVE` files can be used for model inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SHMVCWHkFhJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0fa8657-8250-4102-f9f2-75ab2882bc91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".."
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Check whether the file is ready to be used.\n",
        "while video_file.state.name == \"PROCESSING\":\n",
        "    print('.', end='')\n",
        "    time.sleep(10)\n",
        "    video_file = genai.get_file(video_file.name)\n",
        "\n",
        "if video_file.state.name == \"FAILED\":\n",
        "  raise ValueError(video_file.state.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIIHsvQt0_W"
      },
      "source": [
        "### Prompt with a video and text\n",
        "\n",
        "Once the uploaded video is in the `ACTIVE` state, you can make `GenerateContent` requests that specify the File API URI for that video. Select the generative model and provide it with the uploaded video and a text prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sHH0ZR6Yt42S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "9154ada5-885a-4e46-cb9c-9883a01307ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This video is about Jupiter’s Great Red Spot and the changes it has undergone. The narrator explains that Jupiter is the largest and oldest planet in our solar system, and is made up of the same elements as a star, but it didn’t become massive enough to ignite. Jupiter's appearance is caused by a swirling interior of gasses and liquids which create colored cloud bands and the Great Red Spot. The Great Red Spot is a giant storm, and because there is no landmass to slow it down, it has been active for more than a century. In more recent years, the Great Red Spot’s color has deepened, it’s shrinking and getting rounder. Scientists theorized that as it shrinks, the wind speed increases like an ice skater spinning faster by pulling in their arms, but the data collected by various NASA missions including Voyager, Hubble, and Juno shows the storm isn't spinning faster, it’s getting taller. It used to be large enough to fit three Earths, now it’s only slightly bigger than one. Scientists hope further investigation will shed light on its continued changes. \n\nHere is a quiz on Jupiter's Great Red Spot:\n\n1. Jupiter is the largest and _____ planet in our solar system.\nA. second-oldest\nB. oldest\nC. newest\nD. third-oldest\n\n2. Jupiter’s appearance is the result of the swirling interior of _____ and _____.\nA. gases and lava\nB. liquids and crystals\nC. gases and liquids\nD. gasses and crystals \n\n3. The Great Red Spot is a _____.\nA. volcano\nB. canyon\nC. storm\nD. sinkhole\n\n4. As the Great Red Spot shrinks, the storm is getting _____.\nA. wider\nB. shorter\nC. taller\nD. cooler\n\n5. Which three NASA missions have collected data on Jupiter’s Great Red Spot?\nA. Voyager, Hubble, and Juno\nB. Voyager, Cassini, and Juno\nC. Pioneer, Hubble, and Cassini\nD. Pioneer, Hubble, and Juno\n\n\nAnswer Key:\n1. B\n2. C\n3. C\n4. C\n5. A"
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Create the prompt.\n",
        "prompt = \"Summarize this video. Then create a quiz with answer key based on the information in the video.\"\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Make the LLM request.\n",
        "print(\"Making LLM inference request...\")\n",
        "response = model.generate_content([video_file, prompt],\n",
        "                                  request_options={\"timeout\": 600})\n",
        "\n",
        "# Print the response, rendering any Markdown\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS5NmQeXLqeS"
      },
      "source": [
        "### Refer to timestamps in the content\n",
        "\n",
        "You can use timestamps of the form `MM:SS` to refer to specific moments in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ypZuGQ-2LqeS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "c49f9287-2f56-4bda-a8f5-60a27becf014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The example at [00:00:35] illustrates Jupiter's Great Red Spot and the movement of a smaller moon across it. The example at [00:00:50] shows how the Great Red Spot on Jupiter has changed over time, getting smaller and rounder. "
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Create the prompt.\n",
        "prompt = \"What are the examples given at 00:35 and 00:50 supposed to show us?\"\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Make the LLM request.\n",
        "print(\"Making LLM inference request...\")\n",
        "response = model.generate_content([prompt, video_file],\n",
        "                                  request_options={\"timeout\": 600})\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQE0XjgMZSJo"
      },
      "source": [
        "### Transcribe video and provide visual descriptions\n",
        "\n",
        "The Gemini models can transcribe and provide visual descriptions of video content\n",
        "by processing both the audio track and visual frames.\n",
        "For visual descriptions, the model samples the video at a rate of **1 frame\n",
        "per second**. This sampling rate may affect the level of detail in the\n",
        "descriptions, particularly for videos with rapidly changing visuals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_JrcMsYnYXpJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "ea8a42d9-a4a1-4e03-a5ee-5046843b3a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sure, here’s the transcript of the video with timestamps and visual descriptions. \n\n[00:00:00] In the black of space, Jupiter glows softly, bands of brown, white, and rust-orange swirling across its surface, the Milky Way shimmering faintly in the distance.\n\n[00:00:16] Jupiter’s thin rings become visible as it grows larger in the frame, the swirling surface and the Milky Way growing dimmer in the background.\n\n[00:00:21] With the background fully darkened, Jupiter rotates slowly, its reddish-brown Great Red Spot visible as it approaches the left edge of the planet.\n\n[00:00:27] Zooming in closely on the Great Red Spot, the swirls of its surface become clearer, and Jupiter shrinks in the background as the spot grows.\n\n[00:00:32] As it fills the screen, the moon, Io, passes to its left, and a moon’s shadow briefly passes across the top.\n\n[00:00:42] Pulling away from the Great Red Spot, the view pans out and returns to its place on the left edge of Jupiter.\n\n[00:00:47] The Great Red Spot again approaches the left edge, a close-up image inset over the planet itself.\n\n[00:00:52] The inset image shrinks to show the Great Red Spot as it looked in 1995. The view shifts to show how it looked in 2009, noticeably smaller. The image then shifts to 2015, smaller still and now a darker orange hue.\n\n[00:01:00] As the inset image disappears, the Great Red Spot appears to open up, revealing its swirling interior of orange, red, and rust-colored bands.\n\n[00:01:05] As the ice skater demonstrates how spinning faster pulls her arms in, two graphs of data points show the Great Red Spot’s latitude and its relative height above the Jovian surface. A black line shows the data from 2014. A blue line shows the data from 2015, and a green line shows the data from 2016. The lines rise and fall similarly, with the 2015 line consistently rising a bit higher than the 2014 line, and the 2016 line rising slightly above the 2015 line. A red line showing data from 2017 then appears, again following a similar pattern but with a higher overall rise than the other lines.\n\n[00:01:18] A potter’s hands shape a lump of clay on a spinning wheel, raising it from a rounded lump into a tall, narrow form.\n\n[00:01:25] On the face of Jupiter, the inset image from 1995, 2009, and 2015 are shown again, showing the changing size and shape of the Great Red Spot.\n\n[00:01:32] Earth is superimposed on Jupiter’s face, illustrating that what was once large enough to fit three Earths can now only hold just over one.\n\n[00:01:36] A Voyager space probe, and then the Juno probe, both make their appearance in front of Jupiter.\n\n[00:01:54] The Great Red Spot again fills the screen, its roiling surface a dark orange.\n\n[00:01:59] The Goddard Space Flight Center logo fills the screen, the Earth visible at the edge of the screen.\n\nHope this helps!"
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Create the prompt.\n",
        "prompt = \"Transcribe the audio from this video, giving timestamps for salient events in the video. Also provide visual descriptions.\"\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Make the LLM request.\n",
        "print(\"Making LLM inference request...\")\n",
        "response = model.generate_content([video_file, prompt],\n",
        "                                  request_options={\"timeout\": 600})\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VosrkvAyrx-v"
      },
      "source": [
        "## List files\n",
        "\n",
        "You can list all uploaded files and their URIs using `files.list_files()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "O82e6E2Irzlj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "54e39a4b-20cf-45af-d382-681563b16f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GreatRedSpot.mp4, URI: https://generativelanguage.googleapis.com/v1beta/files/hbhacw2ab69s\n",
            "Jetpack drawing, URI: https://generativelanguage.googleapis.com/v1beta/files/or2e2oavr4h7\n"
          ]
        }
      ],
      "source": [
        "# List all files\n",
        "for file in genai.list_files():\n",
        "    print(f\"{file.display_name}, URI: {file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diCy9BgjLqeS"
      },
      "source": [
        "## Delete files\n",
        "\n",
        "Files are automatically deleted after 2 days. You can also manually delete them using `files.delete()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YYyi5PrKLqeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a2b3b017-f73c-44fd-c59e-dcd3e30720d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted file https://generativelanguage.googleapis.com/v1beta/files/hbhacw2ab69s\n"
          ]
        }
      ],
      "source": [
        "genai.delete_file(video_file.name)\n",
        "print(f'Deleted file {video_file.uri}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TUGAS ML - II - MENGIDENTIFIKASI PLAT NUMBER MOBIL DARI GAMBAR YANG DIUPLOAD"
      ],
      "metadata": {
        "id": "TJQqsdmUFsVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "         name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Tpa3frgDT_aX",
        "outputId": "f72f40da-4d43-4dc0-d266-f63a52c0d46a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-83ef88a7-d9ad-4037-a1c1-4ac4d77fbbe2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-83ef88a7-d9ad-4037-a1c1-4ac4d77fbbe2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving alzacar.jpg to alzacar (1).jpg\n",
            "User uploaded file \"alzacar (1).jpg\" with length 120414 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# Upload the file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename and content of the uploaded file\n",
        "filename = next(iter(uploaded))\n",
        "file_content = uploaded[filename]\n",
        "\n",
        "# Save the file content to a temporary file\n",
        "with open(filename, 'wb') as f:\n",
        "    f.write(file_content)\n",
        "\n",
        "# Upload the temporary file using genai.upload_file\n",
        "license_plate = genai.upload_file(\n",
        "    path=filename,  # Pass the file path\n",
        "    mime_type='image/jpeg',  # Adjust the MIME type if necessary\n",
        "    display_name=\"License Plate\"\n",
        ")\n",
        "\n",
        "print(f\"Uploaded file '{license_plate.display_name}' as: {license_plate.uri}\")\n",
        "\n",
        "# Remove the temporary file\n",
        "os.remove(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "xaa2IMV7WhL0",
        "outputId": "afd45f39-812c-4690-9e82-da9df6966dfd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-08f91156-f62c-4aa3-a759-bee36e3e7eb7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-08f91156-f62c-4aa3-a759-bee36e3e7eb7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving alzacar.jpg to alzacar (2).jpg\n",
            "Uploaded file 'License Plate' as: https://generativelanguage.googleapis.com/v1beta/files/o5xyxcfev6nd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Prompt the model with text and the previously uploaded image.\n",
        "response = model.generate_content([license_plate, \"read the plate number of the image with output example (‘plat_no’: ‘B 1234 ABC’,\t‘vehicle’: ‘car’,‘vehicle_type’: ‘sedan’,\t‘color’: ‘red’,\t‘gate_open’: ‘2024-12-02 18.15.01’,\t‘gate_closed’: ‘N/A’,), use current date time for gate_open value\"])\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "DIiZRmdOXPIu",
        "outputId": "8deb906c-7310-445a-9085-7865f9739c0a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n{\n\t‘plat_no’: ‘SAB 1633 C’,\n\t‘vehicle’: ‘car’,\n\t‘vehicle_type’: ‘hatchback’,\n\t‘color’: ‘white’,\n\t‘gate_open’: ‘2024-07-28 13:59:27’,\n\t‘gate_closed’: ‘N/A’\n}\n```"
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}